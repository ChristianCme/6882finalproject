{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPlot number of male neighbors vs original bias\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Plot number of male neighbors vs original bias\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from util import preprocessWordVecs, removeWords, load_legacy_w2v\n",
    "from loader import load_def_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_biased(word_vectors, subspace, n_biased=500):\n",
    "    \"\"\"\n",
    "    Get vectors with most positive and negative bias wrt subspace.\n",
    "    \"\"\"\n",
    "\n",
    "    biases = {}\n",
    "\n",
    "    for word, vector in word_vectors.items():\n",
    "        # 1d case\n",
    "        bias = np.dot(vector, subspace)\n",
    "        biases[word] = bias\n",
    "\n",
    "    sorted_biases = sorted(list(biases.items()), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    positive_bias = sorted_biases[:n_biased]\n",
    "    negative_bias = list(reversed(sorted_biases[-n_biased:]))\n",
    "\n",
    "    return positive_bias, negative_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Plot_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_multi(biased_embeddings, debiased_embeddings, vocab_path, targets, bias_specific=None, verbose=None):\n",
    "    \"\"\"\n",
    "    For multi-class: bias direction is from mean to extreme\n",
    "    \"\"\"\n",
    "\n",
    "    # load embeddings\n",
    "    print(\"Loading word embeddings...\")\n",
    "    word_vectors, embed_dim = load_legacy_w2v(biased_embeddings)\n",
    "    debiased_vectors, _ = load_legacy_w2v(debiased_embeddings)\n",
    "\n",
    "    # prune\n",
    "    word_vectors = preprocessWordVecs(word_vectors)\n",
    "    debiased_vectors = preprocessWordVecs(debiased_vectors)\n",
    "\n",
    "    def_sets = load_def_sets(vocab_path)\n",
    "\n",
    "    # take first row of def_sets as defining\n",
    "    classes = def_sets[0]\n",
    "\n",
    "    vects = np.zeros((len(classes), embed_dim))\n",
    "    for i, word in enumerate(classes):\n",
    "        if word not in word_vectors:\n",
    "            raise ValueError(word)\n",
    "        vects[i] = word_vectors[word]\n",
    "    mean = vects.mean(0)\n",
    "\n",
    "    directions = np.zeros((len(classes), embed_dim))\n",
    "    for i, word in enumerate(classes):\n",
    "        directions[i] = word_vectors[word] - mean\n",
    "        directions[i] = directions[i] / np.linalg.norm(directions[i])\n",
    "\n",
    "    # remove bias-specific words\n",
    "    if bias_specific is not None:\n",
    "        biased = json.load(open(bias_specific, 'r'))\n",
    "    else:\n",
    "        biased = []\n",
    "    for value in def_sets.values():\n",
    "        biased.extend(value)\n",
    "\n",
    "    word_vectors = removeWords(word_vectors, biased)\n",
    "    debiased_vectors = removeWords(debiased_vectors, biased)\n",
    "\n",
    "    targets = json.load(open(targets, 'r'))\n",
    "    targets = [x[0] for x in targets]\n",
    "    # compute bias for all targets\n",
    "    original_bias = {}\n",
    "\n",
    "    for i, c in enumerate(classes):\n",
    "        original_bias[c] = {}\n",
    "        for word in targets:\n",
    "            if word in word_vectors:\n",
    "                original_bias[c][word] = np.dot(word_vectors[word], directions[i])\n",
    "\n",
    "    print(len(original_bias[classes[0]]))\n",
    "    # get most biased targets\n",
    "    for c, orig_bias in original_bias.items():\n",
    "        sorted_prof_bias = sorted(orig_bias.items(), key=lambda x: x[1], reverse=True)\n",
    "        most_biased_profs = sorted_prof_bias[:10]\n",
    "        most_antibiased_profs = list(reversed(sorted_prof_bias[-10:]))\n",
    "        if verbose:\n",
    "            print(\"Ten most {}-biased targets\".format(c))\n",
    "            print(most_biased_profs)\n",
    "            print(\"Ten most anti-{}-biased targets\".format(c))\n",
    "            print(most_antibiased_profs)\n",
    "            print()\n",
    "\n",
    "    # get 500 most biased words in either direction\n",
    "    positive_words = {}\n",
    "    negative_words = {}\n",
    "    print(\"computing bias of all words in each direction\")\n",
    "    for i, c in enumerate(classes):\n",
    "        positive_bias, negative_bias = get_most_biased(word_vectors, directions[i])\n",
    "        print(\"obtained 500 most positive- and negative-biased words for {}\".format(c))\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Ten most biased for {}:\".format(c))\n",
    "            print(positive_bias[:10])\n",
    "            print(\"Ten most anti-biased for {}\".format(c))\n",
    "            print(negative_bias[:10])\n",
    "            print()\n",
    "\n",
    "        positive_words[c] = [x[0] for x in positive_bias]\n",
    "        negative_words[c] = [x[0] for x in negative_bias]\n",
    "\n",
    "    n_closest = {}\n",
    "    for i, c in enumerate(classes):\n",
    "        pos_words = positive_words[c]\n",
    "        neg_words = negative_words[c]\n",
    "        # get vectors in biased and debiased embeddings\n",
    "        print(\"extracting subset of most biased words for {}\".format(c))\n",
    "        subset_size = len(pos_words) + len(neg_words)\n",
    "        biased_subset = {}\n",
    "        debiased_subset = {}\n",
    "        for i, word in enumerate(pos_words + neg_words):\n",
    "            biased_subset[word] = word_vectors[word]\n",
    "            debiased_subset[word] = debiased_vectors[word]\n",
    "\n",
    "        n_closest[c] = {}\n",
    "        # for each profession, find number of closest numbers that are in the positive class\n",
    "        for word in original_bias[c].keys():\n",
    "            # compute distance to all words in subset\n",
    "            biased_distances = {}\n",
    "            vec = word_vectors[word]\n",
    "            for target, t_vec in biased_subset.items():\n",
    "                biased_distances[target] = np.linalg.norm(t_vec - vec)\n",
    "\n",
    "            debiased_distances = {}\n",
    "            vec = debiased_vectors[word]\n",
    "            for target, t_vec in debiased_subset.items():\n",
    "                debiased_distances[target] = np.linalg.norm(t_vec - vec)\n",
    "\n",
    "            # get 100 closest neighbors, count positive class\n",
    "            closest_biased = sorted(biased_distances.items(), key=lambda x: x[1])[:100]\n",
    "            closest_debiased = sorted(debiased_distances.items(), key=lambda x: x[1])[:100]\n",
    "\n",
    "            n_positive = [0, 0]\n",
    "            for word2, _ in closest_biased:\n",
    "                if word2 in pos_words:\n",
    "                    n_positive[0] += 1\n",
    "\n",
    "            for word2, _ in closest_debiased:\n",
    "                if word2 in pos_words:\n",
    "                    n_positive[1] += 1\n",
    "\n",
    "            n_closest[c][word] = n_positive\n",
    "\n",
    "    print(len(original_bias[classes[0]]))\n",
    "    print(len(n_closest[classes[0]]))\n",
    "\n",
    "    for c in classes:\n",
    "        try:\n",
    "            assert set(n_closest[c].keys()) == set(original_bias[c].keys())\n",
    "        except Exception as e:\n",
    "            print(set(n_closest[c].keys()).symmetric_difference(set(original_bias[c].keys())))\n",
    "            raise e\n",
    "\n",
    "    # plot number of positive neighbors vs. original bias\n",
    "    figs = []\n",
    "    for c in classes:\n",
    "        biases = []\n",
    "        n_neighbors_biased = []\n",
    "        n_neighbors_debiased = []\n",
    "        for word, bias in original_bias[c].items():\n",
    "            biases.append(bias)\n",
    "            n_neighbors_biased.append(n_closest[c][word][0])\n",
    "            n_neighbors_debiased.append(n_closest[c][word][1])\n",
    "\n",
    "        fig = plt.figure(figsize=(4, 2))\n",
    "        ax = fig.add_subplot(111)\n",
    "        # plt.subplot(121)\n",
    "        plt.scatter(biases, n_neighbors_biased, s=1.5, color='c')\n",
    "        # plt.title(\"Original\", fontsize='medium')\n",
    "        ax.text(0.03, 0.88, \"Original\", fontsize='small', transform=ax.transAxes,\n",
    "            horizontalalignment='left')\n",
    "        plt.ylim(0, 100)\n",
    "        plt.tick_params(labelsize=8)\n",
    "\n",
    "        # plot most biased targets\n",
    "        for p, _ in most_biased_profs[:7] + most_antibiased_profs[:7]:\n",
    "            x = original_bias[c][p]\n",
    "            y = n_closest[c][p][0]\n",
    "            # print(p, (x, y))\n",
    "            plt.annotate(p, xy=(x, y),\n",
    "                xytext=(np.random.random()*0.1, np.random.random()*0.1),\n",
    "                textcoords='offset pixels', fontsize='x-small')\n",
    "\n",
    "        plt.show()\n",
    "        figs.append(fig)\n",
    "\n",
    "        fig = plt.figure(figsize=(4, 2))\n",
    "        ax = fig.add_subplot(111)\n",
    "        plt.scatter(biases, n_neighbors_debiased, s=1.5, color='c')\n",
    "        ax.text(0.03, 0.88, f\"Debiased\", fontsize='small', transform=ax.transAxes,\n",
    "            horizontalalignment='left')\n",
    "        plt.ylim(0, 100)\n",
    "        plt.tick_params(labelsize=8)\n",
    "\n",
    "        for p, _ in most_biased_profs[:7] + most_antibiased_profs[:7]:\n",
    "            # print(p)\n",
    "            x = original_bias[c][p]\n",
    "            y = n_closest[c][p][1]\n",
    "            plt.annotate(p, xy=(x, y),\n",
    "                xytext=(np.random.random()*0.1, np.random.random()*0.1),\n",
    "                textcoords='offset pixels', fontsize='x-small')\n",
    "\n",
    "        plt.show()\n",
    "        figs.append(fig)\n",
    "        \n",
    "        print(c)\n",
    "        print(\"biased\")\n",
    "        print(\"Pearson: {}\".format(pearsonr(biases, n_neighbors_biased)))\n",
    "        print(\"Spearman: {}\".format(spearmanr(biases, n_neighbors_biased)))\n",
    "        print(\"debiased\")\n",
    "        print(\"Pearson: {}\".format(pearsonr(biases, n_neighbors_debiased)))\n",
    "        print(\"Spearman: {}\".format(spearmanr(biases, n_neighbors_debiased)))\n",
    "\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_binary(biased_embeddings, debiased_embeddings, vocab_path, targets, bias_specific=None, verbose=None):\n",
    "    # load embeddings\n",
    "    print(\"Loading word embeddings...\")\n",
    "    word_vectors, embed_dim = load_legacy_w2v(biased_embeddings)\n",
    "    debiased_vectors, _ = load_legacy_w2v(debiased_embeddings)\n",
    "\n",
    "    # prune\n",
    "    word_vectors = preprocessWordVecs(word_vectors)\n",
    "    debiased_vectors = preprocessWordVecs(debiased_vectors)\n",
    "\n",
    "    # assume gender direction is just he - she\n",
    "    gender_direction = word_vectors['he'] - word_vectors['she']\n",
    "    gender_direction = gender_direction / np.linalg.norm(gender_direction)\n",
    "    debiased_direction = debiased_vectors['he'] - debiased_vectors['she']\n",
    "\n",
    "    # remove gender-specific words\n",
    "    def_sets = load_def_sets(vocab_path)\n",
    "    if bias_specific is not None:\n",
    "        biased = json.load(open(bias_specific, 'r'))\n",
    "    else:\n",
    "        biased = []\n",
    "\n",
    "    for value in def_sets.values():\n",
    "        biased.extend(value)\n",
    "    word_vectors = removeWords(word_vectors, biased)\n",
    "    debiased_vectors = removeWords(debiased_vectors, biased)\n",
    "\n",
    "    targets = json.load(open(targets, 'r'))\n",
    "    targets = [x[0] for x in targets]\n",
    "    # compute bias for all targets\n",
    "    original_bias = {}\n",
    "    for word in targets:\n",
    "        if word in word_vectors:\n",
    "            original_bias[word] = np.dot(word_vectors[word], gender_direction)\n",
    "\n",
    "    print(len(original_bias))\n",
    "    # get most biased targets\n",
    "    sorted_prof_bias = sorted(original_bias.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Ten most male-biased targets\")\n",
    "        print(sorted_prof_bias[:10])\n",
    "        print(\"Ten most female-biased targets\")\n",
    "        print(list(reversed(sorted_prof_bias[-10:])))\n",
    "        print()\n",
    "\n",
    "    # get 500 most biased words in either direction\n",
    "    print(\"computing bias of all words\")\n",
    "    positive_bias, negative_bias = get_most_biased(word_vectors, gender_direction)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Ten most male-biased\")\n",
    "        print(positive_bias[:10])\n",
    "        print(\"Ten most anti-male-biased\")\n",
    "        print(negative_bias[:10])\n",
    "        print()\n",
    "\n",
    "    print(\"obtained 500 most positive- and negative-biased words\")\n",
    "    positive_words = [x[0] for x in positive_bias]\n",
    "    negative_words = [x[0] for x in negative_bias]\n",
    "\n",
    "    # get vectors in biased and debiased embeddings\n",
    "    print(\"extracting subset of most biased words\")\n",
    "    subset_size = len(positive_words) + len(negative_words)\n",
    "    # biased_subset = np.zeros((subset_size, embed_dim))\n",
    "    # debiased_subset = np.zeros_like(biased_subset)\n",
    "    biased_subset = {}\n",
    "    debiased_subset = {}\n",
    "    for i, word in enumerate(positive_words + negative_words):\n",
    "        biased_subset[word] = word_vectors[word]\n",
    "        debiased_subset[word] = debiased_vectors[word]\n",
    "\n",
    "    # for each profession, find number of closest numbers that are in the positive class\n",
    "    n_closest = {}\n",
    "    for word in original_bias.keys():\n",
    "        # compute distance to all words in subset\n",
    "        biased_distances = {}\n",
    "        vec = word_vectors[word]\n",
    "        for target, t_vec in biased_subset.items():\n",
    "            biased_distances[target] = np.linalg.norm(t_vec - vec)\n",
    "\n",
    "        debiased_distances = {}\n",
    "        vec = debiased_vectors[word]\n",
    "        for target, t_vec in debiased_subset.items():\n",
    "            debiased_distances[target] = np.linalg.norm(t_vec - vec)\n",
    "\n",
    "        # get 100 closest neighbors, count positive class\n",
    "        closest_biased = sorted(biased_distances.items(), key=lambda x: x[1])[:100]\n",
    "        closest_debiased = sorted(debiased_distances.items(), key=lambda x: x[1])[:100]\n",
    "\n",
    "        n_positive = [0, 0]\n",
    "        for word2, _ in closest_biased:\n",
    "            if word2 in positive_words:\n",
    "                n_positive[0] += 1\n",
    "\n",
    "        for word2, _ in closest_debiased:\n",
    "            if word2 in positive_words:\n",
    "                n_positive[1] += 1\n",
    "\n",
    "        n_closest[word] = n_positive\n",
    "\n",
    "    print(len(original_bias))\n",
    "    print(len(n_closest))\n",
    "\n",
    "    try:\n",
    "        assert set(n_closest.keys()) == set(original_bias.keys())\n",
    "    except Exception as e:\n",
    "        print(set(n_closest.keys()).symmetric_difference(set(original_bias.keys())))\n",
    "        raise e\n",
    "\n",
    "    # plot number of positive neighbors vs. original bias\n",
    "    biases = []\n",
    "    n_neighbors_biased = []\n",
    "    n_neighbors_debiased = []\n",
    "    for word, bias in original_bias.items():\n",
    "        biases.append(bias)\n",
    "        n_neighbors_biased.append(n_closest[word][0])\n",
    "        n_neighbors_debiased.append(n_closest[word][1])\n",
    "\n",
    "    plt.figure(figsize=(10, 3.5))\n",
    "    plt.subplot(121)\n",
    "    plt.scatter(biases, n_neighbors_biased, s=1.5)\n",
    "    plt.title(\"Original\")\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.scatter(biases, n_neighbors_debiased, s=2)\n",
    "    plt.title(\"Debiased\")\n",
    "\n",
    "    print(\"Pearson: {}\".format(pearsonr(biases, n_neighbors_biased)))\n",
    "    print(\"Spearman: {}\".format(spearmanr(biases, n_neighbors_biased)))\n",
    "    print(\"Pearson (debiased): {}\".format(pearsonr(biases, n_neighbors_debiased)))\n",
    "    print(\"Spearman (debiased): {}\".format(spearmanr(biases, n_neighbors_debiased)))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word embeddings...\n",
      "253\n",
      "Ten most male-biased targets\n",
      "[('midfielder', 0.45367944395340387), ('goalkeeper', 0.43236988459147735), ('commander', 0.40435483348326995), ('crusader', 0.4012622246447719), ('marshal', 0.3638527696691203), ('commissioner', 0.3532391950118219), ('marksman', 0.3464902749072246), ('baron', 0.34038179842287786), ('chancellor', 0.3243341978092679), ('negotiator', 0.3205027367811598)]\n",
      "Ten most female-biased targets\n",
      "[('stylist', -0.4738521080541447), ('nurse', -0.38619607398686895), ('confesses', -0.3745347852801356), ('maid', -0.3676198762905253), ('therapist', -0.35543224655135786), ('hairdresser', -0.34625982657000914), ('doctor', -0.3409284201024776), ('pediatrician', -0.33976050008529435), ('counselor', -0.330995848088507), ('dermatologist', -0.32514493985155524)]\n",
      "\n",
      "computing bias of all words\n",
      "Ten most male-biased\n",
      "[('cfc', 0.6862915054656281), ('starkiller', 0.6097819604475139), ('eugen', 0.6050943077379223), ('blufor', 0.6018509993206507), ('jsdf', 0.601697894770763), ('nva', 0.6003247438309183), ('saa', 0.599693509655961), ('jets', 0.5986865946689269), ('airpower', 0.589108884717977), ('luftwaffe', 0.588638570977329)]\n",
      "Ten most anti-male-biased\n",
      "[('apnea', -0.5912366398693785), ('miscarried', -0.5846815059519548), ('breastfed', -0.5778640002999216), ('fingering', -0.566988689222693), ('hetero', -0.5637250282734974), ('wifes', -0.5536097736329203), ('kisses', -0.5494475777843026), ('underaged', -0.548563273767354), ('snoring', -0.5471287962372722), ('massage', -0.546771646719215)]\n",
      "\n",
      "obtained 500 most positive- and negative-biased words\n",
      "extracting subset of most biased words\n",
      "253\n",
      "253\n",
      "Pearson: (0.9101355793540616, 4.90944209407237e-98)\n",
      "Spearman: SpearmanrResult(correlation=0.9381921102153161, pvalue=1.1842901873144616e-117)\n",
      "Pearson (debiased): (0.8999475517403616, 1.8101005230572165e-92)\n",
      "Spearman (debiased): SpearmanrResult(correlation=0.9228369715022526, pvalue=5.506669609513596e-106)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x252 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_binary('../data/Manzini/reddit.US.txt.tok.clean.cleanedforw2v_0.w2v', \n",
    "            '../data/Manzini/data_vocab_race_attributes_optm_json_role_hardDebiasedEmbeddingsOut.w2v',\n",
    "            '../data/vocab/race_attributes_optm.json', \n",
    "            '../data/lists/professions.json',\n",
    "           verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
